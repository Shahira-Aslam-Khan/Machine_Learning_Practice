{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import KBinsDiscretizer"
      ],
      "metadata": {
        "id": "QX2dCFkP-H5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('dataset.csv')"
      ],
      "metadata": {
        "id": "-_oxnT8v-K3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Data Shape:\", df.shape)\n",
        "print(df.head())\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "wfvMYMw7-VCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning- replacing missing values with acceptable value\n",
        "num_cols = df.select_dtypes(include=np.number).columns\n",
        "cat_cols = df.select_dtypes(exclude=np.number).columns\n",
        "\n",
        "imputer_num = SimpleImputer(strategy='mean')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
        "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])"
      ],
      "metadata": {
        "id": "wKrJ4m-G-lip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing duplicates\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "yAszYo-z-zJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing outliers\n",
        "for col in num_cols:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    df[col] = np.where(df[col] < lower, lower, df[col])\n",
        "    df[col] = np.where(df[col] > upper, upper, df[col])"
      ],
      "metadata": {
        "id": "-W4UDaxV-5uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"After Cleaning:\", df.shape)"
      ],
      "metadata": {
        "id": "ZjgwUfxj_Cp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "AtUEdGojAqzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('synthetic_data.csv')"
      ],
      "metadata": {
        "id": "pVPwm8qP_nuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Data Shape:\", df2.shape)\n",
        "print(df2.head())\n",
        "print(df2.info())"
      ],
      "metadata": {
        "id": "kMp4j6jp_s7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['stroke']=1"
      ],
      "metadata": {
        "id": "UNXtjmDID2Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['stroke']"
      ],
      "metadata": {
        "id": "J3oUgmt6D5ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning- replacing missing values with acceptable value\n",
        "num_cols = df2.select_dtypes(include=np.number).columns\n",
        "cat_cols = df2.select_dtypes(exclude=np.number).columns\n",
        "\n",
        "imputer_num = SimpleImputer(strategy='mean')\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "df2[num_cols] = imputer_num.fit_transform(df2[num_cols])\n",
        "df2[cat_cols] = imputer_cat.fit_transform(df2[cat_cols])"
      ],
      "metadata": {
        "id": "8T4q9-oh_vy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing duplicates\n",
        "df2.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "KfhFUPCz_yZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing outliers\n",
        "# Drop the 'Unnamed: 0' column if it exists before outlier removal\n",
        "if 'Unnamed: 0' in df2.columns:\n",
        "    df2 = df2.drop('Unnamed: 0', axis=1)\n",
        "    # Update num_cols after dropping the column\n",
        "    num_cols = df2.select_dtypes(include=np.number).columns\n",
        "\n",
        "\n",
        "for col in num_cols:\n",
        "    Q1 = df2[col].quantile(0.25)\n",
        "    Q3 = df2[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    df2[col] = np.where(df2[col] < lower, lower, df2[col])\n",
        "    df2[col] = np.where(df2[col] > upper, upper, df2[col])"
      ],
      "metadata": {
        "id": "MBqK9sst_2gZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"After Cleaning:\", df2.shape)"
      ],
      "metadata": {
        "id": "wpdp66VZ_5Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "metadata": {
        "id": "5Eb-zrESBDjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "tEr009PXCjGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "metadata": {
        "id": "fA0iDw4qCmHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.concat([df, df2], ignore_index=True)\n",
        "\n",
        "print(\"After Integration:\", df1.shape)"
      ],
      "metadata": {
        "id": "y8_aCdG9_OeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding category\n",
        "label_encoders = {}\n",
        "# Redefine categorical columns after concatenation and exclude 'id'\n",
        "cat_cols = df1.select_dtypes(include='object').columns\n",
        "# Convert all categorical columns to string type to ensure consistency\n",
        "for col in cat_cols:\n",
        "    df1[col] = df1[col].astype(str)\n",
        "\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df1[col] = le.fit_transform(df1[col])\n",
        "    label_encoders[col] = le"
      ],
      "metadata": {
        "id": "3_1vN106C81K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature scaling (Normalization/standardization)\n",
        "scaler = StandardScaler()\n",
        "df1[num_cols] = scaler.fit_transform(df1[num_cols])\n",
        "\n",
        "print(\"âœ… After Transformation:\")\n",
        "print(df1.head())"
      ],
      "metadata": {
        "id": "qsbu8h1ADEwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "iKLHo2vIDU-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['stroke']"
      ],
      "metadata": {
        "id": "4hGPMp80FLAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['stroke'] = df1['stroke'].astype(int)"
      ],
      "metadata": {
        "id": "jVSuGfkPFeqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['stroke']"
      ],
      "metadata": {
        "id": "7BaRSJ7rGCcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dataset to 2 principal components\n",
        "pca = PCA(n_components=2)\n",
        "pca_features = pca.fit_transform(df1[num_cols])"
      ],
      "metadata": {
        "id": "6_adZ4HWGhRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new DataFrame for PCA results\n",
        "df_pca = pd.DataFrame(pca_features, columns=['PCA1', 'PCA2'])"
      ],
      "metadata": {
        "id": "DZSWocyZGuCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine PCA data with the original\n",
        "df_final = pd.concat([df1, df_pca], axis=1)\n",
        "\n",
        "print(\"After PCA Dimensionality Reduction:\")\n",
        "print(df_final.head())"
      ],
      "metadata": {
        "id": "pHJvG5DLGzuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.to_csv('preprocessed_data.csv', index=False)\n",
        "print(\"Preprocessed data saved as 'preprocessed_data.csv'\")"
      ],
      "metadata": {
        "id": "3uOejxC-HRJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.info(\n",
        ")"
      ],
      "metadata": {
        "id": "R8Db6vkFHczB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.describe()"
      ],
      "metadata": {
        "id": "XB-WobcRHg7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MRjPB8WWHk3I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}